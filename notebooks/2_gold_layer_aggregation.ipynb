{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "199db669-4714-45c2-bda8-734ccb2d7ce9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, sum, avg, count, date_trunc\n",
    "\n",
    "# --- PART 1: SETUP & MOUNTING ---\n",
    "storage_account_name = \"STORAGE ACCOUNT NAME\" # <--- UPDATE THIS\n",
    "storage_account_key = \"KEY\" # <--- UPDATE THIS\n",
    "container_name = \"gold\"\n",
    "\n",
    "source_url = f\"wasbs://{container_name}@{storage_account_name}.blob.core.windows.net/\"\n",
    "mount_point = f\"/mnt/{container_name}\"\n",
    "extra_configs = {f\"fs.azure.account.key.{storage_account_name}.blob.core.windows.net\": storage_account_key}\n",
    "\n",
    "# Mount Gold if not already mounted\n",
    "if not any(mount.mountPoint == mount_point for mount in dbutils.fs.mounts()):\n",
    "    dbutils.fs.mount(source=source_url, mount_point=mount_point, extra_configs=extra_configs)\n",
    "    print(f\"Mounted {mount_point} successfully!\")\n",
    "else:\n",
    "    print(f\"{mount_point} is already mounted.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b42ecb5-f8cb-4ccf-bcce-66eeaeea71a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --- PART 2: BUSINESS LOGIC (Aggregations) ---\n",
    "# We read from the Clean Silver Tables we created in Notebook 2\n",
    "# Note: We group by Month and Zone to get a high-level summary.\n",
    "\n",
    "gold_df = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        -- 1. Keep the raw date for sorting/Time Intelligence\n",
    "        date_trunc('month', t.pickup_time) AS report_date,\n",
    "        \n",
    "        -- 2. Extract readable columns for Power BI\n",
    "        year(t.pickup_time) AS report_year,\n",
    "        concat('Q', quarter(t.pickup_time)) AS report_quarter, \n",
    "        date_format(t.pickup_time, 'MMMM') AS report_month_name,\n",
    "        \n",
    "        -- 3. The Business Dimensions\n",
    "        z.Borough,\n",
    "        z.Zone,\n",
    "        \n",
    "        -- 4. The Metrics\n",
    "        count(t.vendor_id) AS total_trips,\n",
    "        sum(t.total_amount) AS total_revenue,\n",
    "        avg(t.trip_distance) AS avg_distance,\n",
    "        avg(t.passenger_count) AS avg_passenger_count\n",
    "    FROM urban_mobility.silver_taxi t\n",
    "    LEFT JOIN urban_mobility.taxi_zone_lookup z\n",
    "        ON t.PULocationID = z.LocationID\n",
    "    GROUP BY 1, 2, 3, 4, 5, 6\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7e0bf1e-6c96-471a-ad7e-429d71c79c46",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1765991783298}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --- PART 3: WRITE TO GOLD ---\n",
    "gold_path = \"/mnt/gold/monthly_revenue_by_zone\"\n",
    "\n",
    "gold_df.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .save(gold_path)\n",
    "\n",
    "# --- PART 4: REGISTER TABLE ---\n",
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS urban_mobility_gold\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS urban_mobility_gold.monthly_revenue_by_zone\n",
    "    USING DELTA\n",
    "    LOCATION '/mnt/gold/monthly_revenue_by_zone'\n",
    "\"\"\")\n",
    "\n",
    "print(\"Success! Gold Table created.\")\n",
    "display(gold_df)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "2_gold_layer_aggregation",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
